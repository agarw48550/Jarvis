# LLM configuration (OpenAI-compatible)
# Using your local server at http://127.0.0.1:1234
LLM_API_KEY=
LLM_BASE_URL=http://127.0.0.1:1234
LLM_MODEL=qwen/qwen3-4b-2507

# Notion API: https://www.notion.so/my-integrations
NOTION_API_KEY=
NOTION_DEFAULT_DATABASE_ID=

# Google Calendar OAuth
# Place OAuth client JSON at credentials.json (desktop app) in project root.
# token.json will be created on first auth.

# TinyTuya (SmartLife) devices
# Fill device mappings in config.yaml

# General
LOG_LEVEL=INFO
FACTCHECK_ALWAYS=1
TIMEZONE=Asia/Singapore
LLM_DEBUG=0
LLM_TIMEOUT=30
GRACEFUL_TIMEOUT_SECONDS=5

# TTS configuration
# Primary engine selection: elevenlabs | edge | say | piper | kokoro | marytts
TTS_ENGINE=elevenlabs
TTS_DEBUG=0
# If 1, do not fall back when ElevenLabs fails; audio will be suppressed with a console warning
TTS_STRICT=0
# Fallback engine to use if ElevenLabs fails and TTS_STRICT=0
TTS_FALLBACK_ENGINE=say
# Retry attempts for ElevenLabs before falling back
TTS_RETRIES=2

# Fill these with your credentials (do NOT commit your real keys)
ELEVENLABS_API_KEY=
ELEVENLABS_VOICE_ID=
ELEVENLABS_MODEL_ID=eleven_multilingual_v2

# Fallback (local): macOS 'say' voice
TTS_VOICE=Daniel
TTS_RATE_WPM=200

# Piper (local CLI) â€” download model + config from VOICES.md and point to them
PIPER_BIN=tools/piper/piper/piper
PIPER_MODEL_PATH=/absolute/path/to/en_US-ryan-medium.onnx
PIPER_CONFIG_PATH=/absolute/path/to/en_US-ryan-medium.onnx.json
PIPER_NOISE_SCALE=0.7
PIPER_LENGTH_SCALE=1.0

# Kokoro (local HTTP)
KOKORO_BASE_URL=http://127.0.0.1:8000
#KOKORO_VOICE=daniel  # aliases: daniel->am_michael, ryan->am_adam, amy->af_nicole, michael->am_michael
#KOKORO_SPEED=1.2      # 1.0 normal; >1.0 faster, <1.0 slower

# MaryTTS (local Java server)
MARYTTS_BASE_URL=http://127.0.0.1:59125
MARYTTS_VOICE=dfki-pavoque-neutral

# STT tuning (seconds)
STT_TIMEOUT=8
STT_MAX_SECONDS=30

# Source presentation controls
# If 1, show a Sources section with URLs in the console after grounded answers
PRINT_SOURCES=1
# If 1, the TTS will speak bracket citations like [1]; if 0, they will be omitted when speaking
TTS_SPEAK_CITATIONS=0

# Wake word (Porcupine)
PICOVOICE_ACCESS_KEY=
# Preferred built-in keyword; falls back to 'jarvis' if not available
WAKEWORD_KEYWORD=jarvis
# Optional: path to custom .ppn file
WAKEWORD_KEYWORD_PATH=
# Sensitivity (0.0â€“1.0). Higher is more sensitive.
WAKEWORD_SENSITIVITY=0.6
# Optional: input device index; leave blank for default
WAKE_INPUT_DEVICE_INDEX=

# Wake mode
WAKE_MODE=1

# Shortcuts aliases (optional)
# Map phrases to shortcut names, either JSON or simple pairs separated by ';'
# Example (pairs):
# SHORTCUTS_ALIASES=focus mode:Work and Basic; open notes:Open Notes
# Example (JSON):
# SHORTCUTS_ALIASES={"focus mode":"Work and Basic","open notes":"Open Notes"}

# Streaming generation (speak while the LLM is still generating)
LLM_STREAM=1
